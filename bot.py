from aiogram.types import BotCommand
import random
import torch
import torchvision.transforms as transforms
import torchvision.models as models
from aiogram import Bot, Dispatcher, types
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.utils import executor
from PIL import Image
import io
import os
import glob

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞
TOKEN = "7803258791:AAE1sFkqfQyQjeea-E1TImzCI4z6d9B5xuk"

# –°–æ–∑–¥–∞—ë–º –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä
bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

async def set_commands():
    commands = [
        BotCommand(command="/start", description="–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞"),
    ]
    await bot.set_my_commands(commands)

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å –∫–Ω–æ–ø–∫–∞–º–∏
keyboard = ReplyKeyboardMarkup(resize_keyboard=True)
keyboard.add(KeyboardButton("/start"))
keyboard.add(KeyboardButton("–°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑"))
keyboard.add(KeyboardButton("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±"))
keyboard.add(KeyboardButton("–û—á–∏—Å—Ç–∏—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±"))

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ MobileNetV3
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)
model.classifier[3] = torch.nn.Linear(in_features=1024, out_features=2)  # –í–µ—Ä—Ö (0) / –ù–∏–∑ (1)
model.load_state_dict(torch.load("clothing_model.pth", map_location=device))  # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤
model.eval().to(device)

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# –ü–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
os.makedirs("images/top", exist_ok=True)
os.makedirs("images/bottom", exist_ok=True)

def classify_image(image: Image.Image) -> str:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –≤–µ—Ä—Ö (1) –∏–ª–∏ –Ω–∏–∑ (0)."""
    image = transform(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image)
        prediction = torch.argmax(output, dim=1).item()
    return "–≤–µ—Ä—Ö" if prediction == 1 else "–Ω–∏–∑"

@dp.message_handler(commands=['start'])
async def start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã, –∏ —è —Ä–∞–∑–±–µ—Ä—É, —á—Ç–æ —ç—Ç–æ.\n\n"
        "üìå –ò—Å–ø–æ–ª—å–∑—É–π –∫–Ω–æ–ø–∫–∏:\n"
        "‚úÖ /start ‚Äì –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞\n"
        "‚úÖ –°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑ ‚Äì –°–ª—É—á–∞–π–Ω—ã–π –∫–æ–º–ø–ª–µ–∫—Ç\n"
        "‚úÖ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–± ‚Äì –í—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≤–µ—â–∏\n"
        "‚úÖ –û—á–∏—Å—Ç–∏—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–± ‚Äì –£–¥–∞–ª–∏—Ç—å –≤—Å–µ –≤–µ—â–∏",
        reply_markup=keyboard
    )

@dp.message_handler(content_types=['photo'])
async def handle_photo(message: types.Message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–æ—Ç–æ, –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º."""
    os.makedirs("images/temp", exist_ok=True)  # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ
    filename = f"{message.photo[-1].file_id}.jpg"
    image_path = f"images/temp/{filename}"

    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å
    await message.photo[-1].download(destination_file=image_path)

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å–∫–∞—á–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = Image.open(image_path).convert("RGB")

    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    category = classify_image(image)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    save_path = f"images/{'top' if category == '–≤–µ—Ä—Ö' else 'bottom'}/{filename}"
    image.save(save_path)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º

    await message.answer(f"–§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category}!")  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç

@dp.message_handler(lambda message: message.text == "–°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑")
async def assemble_outfit(message: types.Message):
    """–í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –≤–µ—Ä—Ö –∏ –Ω–∏–∑, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."""
    tops = os.listdir("images/top")
    bottoms = os.listdir("images/bottom")

    if not tops or not bottoms:
        await message.answer("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ñ–æ—Ç–æ –¥–ª—è —Å–±–æ—Ä–∫–∏ –æ–±—Ä–∞–∑–∞! –î–æ–±–∞–≤—å –±–æ–ª—å—à–µ –≤–µ—â–µ–π.")
        return

    top_image = Image.open(f"images/top/{random.choice(tops)}")
    bottom_image = Image.open(f"images/bottom/{random.choice(bottoms)}")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    width = max(top_image.width, bottom_image.width)
    new_height = top_image.height + bottom_image.height
    outfit = Image.new("RGB", (width, new_height), (255, 255, 255))
    outfit.paste(top_image, (0, 0))
    outfit.paste(bottom_image, (0, top_image.height))

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
    output_path = "outfit.jpg"
    outfit.save(output_path)
    with open(output_path, "rb") as photo:
        await message.answer_photo(photo, caption="–¢–≤–æ–π —Å–ª—É—á–∞–π–Ω—ã–π –æ–±—Ä–∞–∑!")

@dp.message_handler(lambda message: message.text == "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±")
async def view_closet(message: types.Message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤—Å–µ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã."""
    top_files = glob.glob("images/top/*.jpg")
    bottom_files = glob.glob("images/bottom/*.jpg")

    if not top_files and not bottom_files:
        await message.answer("–ì–∞—Ä–¥–µ—Ä–æ–± –ø—É—Å—Ç! –î–æ–±–∞–≤—å –æ–¥–µ–∂–¥—É.")
        return

    await message.answer("–¢–≤–æ–π –≥–∞—Ä–¥–µ—Ä–æ–±:")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –≤–µ—Ä—Ö–∞
    if top_files:
        await message.answer("üëï –í–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞:")
        for file in top_files:
            with open(file, "rb") as photo:
                await message.answer_photo(photo)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –Ω–∏–∑–∞
    if bottom_files:
        await message.answer("üëñ –ù–∏–∂–Ω—è—è –æ–¥–µ–∂–¥–∞:")
        for file in bottom_files:
            with open(file, "rb") as photo:
                await message.answer_photo(photo)

@dp.message_handler(lambda message: message.text == "–û—á–∏—Å—Ç–∏—Ç—å –≥–∞—Ä–¥–µ—Ä–æ–±")
async def clear_closet(message: types.Message):
    """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≤–µ—â–∏."""
    for folder in ["images/top", "images/bottom"]:
        files = glob.glob(f"{folder}/*.jpg")
        for file in files:
            os.remove(file)

    await message.answer("–ì–∞—Ä–¥–µ—Ä–æ–± –æ—á–∏—â–µ–Ω! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å –Ω–æ–≤—É—é –æ–¥–µ–∂–¥—É.")

async def on_startup(_):
    await set_commands()

executor.start_polling(dp, skip_updates=True)
